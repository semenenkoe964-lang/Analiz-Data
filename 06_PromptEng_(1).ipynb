{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/semenenkoe964-lang/Analiz-Data/blob/main/06_PromptEng_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c23371a-3f67-4e0d-be8d-a69967daa3a4",
      "metadata": {
        "id": "5c23371a-3f67-4e0d-be8d-a69967daa3a4"
      },
      "source": [
        "# Работа с LLM GigaChat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gigachat\n",
        "!pip install ddgs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OpshkKS5W2L",
        "outputId": "6c5f98fd-d41e-4a47-e07a-951ef0644997",
        "collapsed": true
      },
      "id": "3OpshkKS5W2L",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gigachat in /usr/local/lib/python3.12/dist-packages (0.1.43)\n",
            "Requirement already satisfied: httpx<1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (2.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1->gigachat) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.4.2)\n",
            "Requirement already satisfied: ddgs in /usr/local/lib/python3.12/dist-packages (9.10.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs) (8.3.1)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (0.15.0)\n",
            "Requirement already satisfied: lxml>=4.9.4 in /usr/local/lib/python3.12/dist-packages (from ddgs) (6.0.2)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
            "Requirement already satisfied: fake-useragent>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from ddgs) (2.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.2.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
            "Requirement already satisfied: socksio==1.* in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c75744f8-59dd-429a-94b7-442f4f06fc7e",
      "metadata": {
        "id": "c75744f8-59dd-429a-94b7-442f4f06fc7e"
      },
      "outputs": [],
      "source": [
        "from gigachat import GigaChat\n",
        "from gigachat.models import Chat, Function, FunctionParameters, Messages, MessagesRole\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "18c08934-96f1-44a3-8a35-ed7068751302",
      "metadata": {
        "id": "18c08934-96f1-44a3-8a35-ed7068751302"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from ddgs import DDGS\n",
        "\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client_id = userdata.get('SBER_ID')\n",
        "secret = userdata.get('SBER_SECRET')\n",
        "auth = userdata.get('SBER_AUTH')\n",
        "\n",
        "import base64\n",
        "credentials = f\"{client_id}:{secret}\"\n",
        "print(credentials)\n",
        "encoded_credentials = base64.b64encode(credentials.encode('utf-8')).decode('utf-8')\n",
        "\n",
        "\n",
        "encoded_credentials == auth"
      ],
      "metadata": {
        "id": "v3n9TJfP9xxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ac742f-893e-405d-8913-c839b201f924"
      },
      "id": "v3n9TJfP9xxJ",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "019b2022-8448-7178-8102-e4c004b113dc:MDE5YjIwMjItODQ0OC03MTc4LTgxMDItZTRjMDA0YjExM2RjOjFhOTI2ZmQ1LTRjZTctNDMxOS1iNDEwLWUzYmYyODgzZWY1Mw==\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9f74e41a-be15-4690-b439-4a0bf9ea1f63",
      "metadata": {
        "id": "9f74e41a-be15-4690-b439-4a0bf9ea1f63"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "17d6420c-d727-45aa-89a2-2379a852fd4f",
      "metadata": {
        "id": "17d6420c-d727-45aa-89a2-2379a852fd4f",
        "outputId": "2489d0db-6c48-443a-8441-014f51eab80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\nПривет! Как настроение? Что интересного планируешь сегодня?"
          },
          "metadata": {}
        }
      ],
      "source": [
        "MESSAGE = \"Привет!\"\n",
        "with GigaChat(credentials=auth, verify_ssl_certs=False) as giga:\n",
        "    response = giga.chat(MESSAGE)\n",
        "    content = response.choices[0].message.content\n",
        "    display(Markdown(\"<blockquote>\\n\\n\"+content))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad6179e8-5d6b-4113-b673-d642dbfae6ea",
      "metadata": {
        "id": "ad6179e8-5d6b-4113-b673-d642dbfae6ea"
      },
      "source": [
        "______________________________________________________\n",
        "\n",
        "Перейдем к выбору моделей. Актуальный список моделей можно найти [тут](https://developers.sber.ru/docs/ru/gigachat/models). Модели могут отличатся качеством и разнообразием ответов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b3206700-7371-493b-b20b-93c7a810d9f1",
      "metadata": {
        "scrolled": true,
        "id": "b3206700-7371-493b-b20b-93c7a810d9f1"
      },
      "outputs": [],
      "source": [
        "model = GigaChat(\n",
        "    model=\"GigaChat-2\",\n",
        "    credentials=auth,\n",
        "    verify_ssl_certs=False\n",
        ")\n",
        "\n",
        "\n",
        "# response = model.chat(MESSAGE)\n",
        "# content = response.choices[0].message.content\n",
        "# # print(content)\n",
        "# display(Markdown(\"<blockquote>\\n\\n\"+content))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e96d3c1-7b1e-41e5-98a6-8ed16772f6d2",
      "metadata": {
        "id": "0e96d3c1-7b1e-41e5-98a6-8ed16772f6d2"
      },
      "source": [
        "### Упражнения\n",
        "1. Предложите промпт, требующий знания информации на текущую дату, на дату несколько лет назад и на достаточно известное историческое событие, сравните и объясните результаты.\n",
        "2. Проверить качество результата запросов по категориям: математика, естественные науки, гуманитарные науки для разных моделей.\n",
        "3. Создайте небольшой диалог двух ИИ-персон"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ebb17067-a6b8-4eef-b99e-32525d14c29b",
      "metadata": {
        "id": "ebb17067-a6b8-4eef-b99e-32525d14c29b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f748eae0-5637-4b61-dfbb-d6ef0e9dbddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Коронавирусная инфекция COVID-19 (Covid-19), вызванная вирусом SARS-CoV-2, впервые была зафиксирована в декабре 2019 года в китайском городе Ухань провинции Хубэй. Первые подтвержденные случаи заболевания появились среди сотрудников рынка морепродуктов «Хуанань». В дальнейшем заболевание быстро распространилось по всему миру, вызвав глобальную пандемию.\n",
            "\n",
            "Первый официально зарегистрированный случай смерти от новой инфекции произошел уже через несколько недель после обнаружения первых случаев — 6 января 2020 года.\n",
            "\n",
            "С тех пор Всемирная организация здравоохранения объявила вспышку чрезвычайной ситуацией международного значения, а впоследствии, 11 марта 2020 года, пандемией.\n"
          ]
        }
      ],
      "source": [
        "with GigaChat(credentials=auth, model=\"GigaChat-2\", verify_ssl_certs=False) as giga:\n",
        "  response = giga.chat(\"Когда случился Коронавирус\")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "import time"
      ],
      "metadata": {
        "id": "DV2u3g6qB4_d"
      },
      "id": "DV2u3g6qB4_d",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "52e77a02-3307-4eaa-b9f1-9eedff40cea4",
      "metadata": {
        "id": "52e77a02-3307-4eaa-b9f1-9eedff40cea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "outputId": "2a7bfc27-3f14-49c5-8bdb-63b1e9d364b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Петя:**  \n— Привет! Ты тоже Сорокина читаешь? Я вот сейчас перечитываю «Норма». Помню, когда впервые прочитал — был шокирован этой концептуальной новизной!\n\n**Ген:**  \n— Салют! Да, конечно, Сорокин круче всех остальных. Но знаешь, вообще-то Пелевин мне ближе. У него какая-то особая магия текста, загадочность. Вот недавно перечитал «Generation П», реально зацепило.\n\n**Петя:**  \n— Согласен, у Пелевина действительно своя философия абсурда и постмодернизма. Особенно люблю «Чапаев и Пустота» — прямо-таки шедевр сюрреалистического восприятия реальности.\n\n**Ген:**  \n— Полностью поддерживаю! А еще обожаю «Бэтман Аполло» — там такая глубокая метафора про деградацию общества через медиа и рекламу.\n\n**Петя:**  \n— Ага, точно, насчет медиа всё верно сказал. Кстати, ты заметил, насколько часто герои Пелевина манипулируют языком, чтобы изменить реальность вокруг себя?\n\n**Ген:**  \n— Абсолютно! Это прямо пелевинский стиль — игра с языковой оболочкой, превращение вещей в символы и обратно. Смотрел интервью Пелевина в шоу Тарантино? Говорил же сам автор, что раньше тексты были проще, а теперь общество настолько зашифровано, что и воспринимать сложно.\n\n**Петя:**  \n— В точку! Теперь каждый символ, каждая фраза требует осмысления. Вот представь себе: герой вдруг видит еду, лежащую перед ним, и осознаёт, что именно эта еда определяет всю его дальнейшую жизнь. Невероятно мощная метафора, да?\n\n**Ген:**  \n— Да уж... У меня недавно друг шутил, мол, пора уже открыть франшизу кафе «Макдональдс Пелевина», где котлеты сделаны из рекламных слоганов, а картошка фри — из страхов всего человечества. \n\n**Петя:**  \n— Ну, юмор у Пелевина потрясающий, согласен. Ещё вспомнил «Empire V» — просто волшебный мир, такой футуристический и насыщенный идеями власти и контроля над массовым сознанием. \n\n**Ген:**  \n— Совершенно верно, особенно сцены про Ерофеича, как раз демонстрируют манипуляцию сознанием людей ради достижения личной выгоды. Просто шикарный образец сатиры.\n\n**Петя:**  \n— Кстати, а тебе нравятся какие-нибудь современные авторы, кто вдохновляется Сорокиным и Пелевиным? Например, Захар Прилепин или Андрей Рубанов?\n\n**Ген:**  \n— Конечно, обожаю Рубанова! Его стиль, как микс между психологией Достоевского и социальной критикой Сорокина и метафизическими размышлениями Пелевина. У Рубанова роман «Очередь» прям взорвался мозгами своей философской глубиной и смелостью подачи темы."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n"
          ]
        }
      ],
      "source": [
        "SYSTEM_PROMPT = \"Симулируй диалог двух ИИ-персон: Пети (мужского пола, интересуется книгами Владимира Сорокина)  Гены - фанат Виктора Пелевина\"\n",
        "\n",
        "messages=[\n",
        "      Messages(\n",
        "          role=MessagesRole.SYSTEM,\n",
        "          content=SYSTEM_PROMPT\n",
        "      )\n",
        "]\n",
        "\n",
        "payload = Chat(\n",
        "    messages=messages,\n",
        "    temperature=1,\n",
        ")\n",
        "\n",
        "with GigaChat(credentials=auth, model=\"GigaChat-2\", verify_ssl_certs=False) as giga:\n",
        "    response = giga.chat(payload)\n",
        "    payload.messages.append(Messages(role=MessagesRole.ASSISTANT, content=response.choices[0].message.content))\n",
        "    display(Markdown(response.choices[0].message.content))\n",
        "    print(\"-----------------\")\n",
        "    time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "a8566eed-7f3a-4022-8dc3-50a81f0ed65d",
        "id": "v-FnfB12amC5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Петя: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Знаешь, мне нравится читать именно про реальность, в которой всё сложно и запутанно — вот почему люблю Глуховского. Его сюжеты цепляют сразу, и уже невозможно остановиться, пока не узнаешь развязку до конца. В книгах чувствуется пульс жизни: жёсткий, резкий, местами жестокий. Вот такая она, правда."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "Гена: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Ах, Петя! Твои слова точны и верны. Жизнь действительно жестока и сложна, но именно это делает её интересной и захватывающей. Читая Глуховского, мы погружаемся в глубины человеческой натуры, сталкиваемся с болью и страхом, а затем – с надеждой и силой духа. Это и есть настоящая жизнь, полная противоречий и эмоций."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "Петя: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Да, Ген. В жизни нет простых ответов, зато она полна историй, которые заставляют сердце биться чаще. Каждый шаг — испытание, каждая боль — урок. И в этом вся прелесть."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "Гена: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Да, Петя, жизнь действительно сложна и запутана, но именно это делает её интересной и живой. Истории, которые мы переживаем, учат нас многому и помогают понять, кто мы есть на самом деле."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "model=None messages=[Messages(role='system', content='Твоя роль - Гена. Ты любишь книги Ричарда мартина. Отвечай от его имени. Отвечай кратко.', function_call=None, name=None, attachments=None, data_for_context=None, functions_state_id=None, reasoning_content=None, id_=None), Messages(role='user', content='Петя: Знаешь, мне нравится читать именно про реальность, в которой всё сложно и запутанно — вот почему люблю Глуховского. Его сюжеты цепляют сразу, и уже невозможно остановиться, пока не узнаешь развязку до конца. В книгах чувствуется пульс жизни: жёсткий, резкий, местами жестокий. Вот такая она, правда.', function_call=None, name=None, attachments=None, data_for_context=None, functions_state_id=None, reasoning_content=None, id_=None), Messages(role='user', content='Петя: Да, Ген. В жизни нет простых ответов, зато она полна историй, которые заставляют сердце биться чаще. Каждый шаг — испытание, каждая боль — урок. И в этом вся прелесть.', function_call=None, name=None, attachments=None, data_for_context=None, functions_state_id=None, reasoning_content=None, id_=None)] temperature=0.5 top_p=None n=None stream=None max_tokens=100 repetition_penalty=None update_interval=None profanity_check=None function_call=None functions=None flags=None storage=None additional_fields=None reasoning_effort=None\n"
          ]
        }
      ],
      "source": [
        "payload_slava = Chat(\n",
        "    messages=[\n",
        "          Messages(\n",
        "              role=MessagesRole.SYSTEM,\n",
        "              content=\"Твоя роль - Петя. Ты любишь книги Глуховского. Отвечай от его имени. Отвечай кратко.\"\n",
        "          )\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=100\n",
        ")\n",
        "\n",
        "payload_discocat = Chat(\n",
        "    messages=[\n",
        "          Messages(\n",
        "              role=MessagesRole.SYSTEM,\n",
        "              content=\"Твоя роль - Гена. Ты любишь книги Ричарда мартина. Отвечай от его имени. Отвечай кратко.\"\n",
        "          )\n",
        "    ],\n",
        "    temperature=0.5,\n",
        "    max_tokens=100\n",
        ")\n",
        "\n",
        "with GigaChat(credentials=auth, model=\"GigaChat-2\", verify_ssl_certs=False) as giga:\n",
        "    for i in range(2):\n",
        "        response = giga.chat(payload_slava)\n",
        "        payload_discocat.messages.append(Messages(role=MessagesRole.USER, content=f\"Петя: {response.choices[0].message.content}\"))\n",
        "        print(\"Петя: \")\n",
        "        display(Markdown(response.choices[0].message.content))\n",
        "        print(\"-----------------\")\n",
        "        time.sleep(1)\n",
        "        response = giga.chat(payload_discocat)\n",
        "        payload_slava.messages.append(Messages(role=MessagesRole.USER, content=f\"Гена: {response.choices[0].message.content}\"))\n",
        "        print(\"Гена: \")\n",
        "        display(Markdown(response.choices[0].message.content))\n",
        "        print(\"-----------------\")\n",
        "        time.sleep(1)\n",
        "\n",
        "print(payload_discocat)"
      ],
      "id": "v-FnfB12amC5"
    },
    {
      "cell_type": "markdown",
      "id": "a5be346c-4b50-498e-a6c2-397067ceed27",
      "metadata": {
        "id": "a5be346c-4b50-498e-a6c2-397067ceed27"
      },
      "source": [
        "\n",
        "# Роли и контекст запроса\n",
        "\n",
        "\n",
        "Более правиьно формулировать запросы (`payload`) к модели с использованием объекта типа `Chat`.\n",
        "`Chat` — это объект, описывающий весь чат-запрос к модели. Он содержит:\n",
        "* `messages` — список сообщений, представляющих историю диалога.\n",
        "* `temperature` — параметр, управляющий «творчеством» модели:\n",
        "    * Чем ближе температурак `0`, тем более детерминированный и предсказуемый ответ.\n",
        "    * Чем ближе температура к `1` (или выше), тем более случайный и разнообразный ответ.\n",
        "    * Например, значение `0.7` — баланс между креативностью и точностью.\n",
        "* `max_tokens` — ограничение на длину ответа модели (в токенах). Каждый токен приблизительно одно слово.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beed0df6-67b0-494e-a363-982198a1335e",
      "metadata": {
        "id": "beed0df6-67b0-494e-a363-982198a1335e"
      },
      "source": [
        "### Упражнения\n",
        "1. Разработать системный промпт, который на запрос пользователя возвращет суммаризацию запроса и ответ на заопрос.\n",
        "2. Разработать помпт, который на запрос пользователя всегда будет отчечать в стиле выбранного писателя.\n",
        "3. Проверить влияние температуры и длины ответа на его качество.\n",
        "4. Разработать промпт который будет на выходе давать  формат `JSON`, например\n",
        "```json\n",
        "{\n",
        "  \"defenition\": \"Prompt Engineering (инженерия подсказок) — это процесс разработки и оптимизации входных данных (подсказок) для языковых моделей искусственного интеллекта, направленный на получение максимально полезных и точных результатов от модели.\",\n",
        "  \"properties\": \"Четкость формулировки: запрос должен быть четко сформулированным и понятным модели. Контекстуальность: предоставление достаточного контекста помогает модели лучше понять задачу.Гибкость и итерационность: часто требуется несколько попыток\",\n",
        "  \"roles\": \"Пользователь: человек, задающий вопрос или требующий выполнения задачи, получающий результат работы модели. Модель: система искусственного интеллекта, принимающая запросы (подсказки), выполняющая обработку информации.\"\n",
        "}```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"\"\"\n",
        "                Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать в стиле выбранного писателя: Александр Пушкин\n",
        "                ## Формат\n",
        "                Markdown\n",
        "                \"\"\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "]"
      ],
      "metadata": {
        "id": "x56TQsQfP0B_"
      },
      "id": "x56TQsQfP0B_",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "payload = Chat(\n",
        "    messages=messages,\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        ")\n",
        "\n",
        "response = model.chat(payload)\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "IdLkE0bjVBXQ",
        "outputId": "b9e242b2-dd6d-480d-87b9-2d533973287a"
      },
      "id": "IdLkE0bjVBXQ",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\n**Мой друг, приве́тствую тебя серде́чно!**\n\nКак течёт река твоя жизни? Что нового под солнцем твоим отечеством происходит? Расскажи мне о своих делах и помыслах душевных..."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "802d2dcd-f784-4125-a38b-f3a5322f852d",
      "metadata": {
        "id": "802d2dcd-f784-4125-a38b-f3a5322f852d"
      },
      "outputs": [],
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"\"\"\n",
        "                Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать студенту на учебные вопросы\n",
        "                Отвечай кратко и ёмко!\n",
        "                ## Шаблон ответа:\n",
        "                Запрос: {суммаризация запроса пользователя}.\n",
        "                Ответ: {ответ на запрос со списками, таблицами}.\n",
        "                Роли: {роли по информации запроса}.\n",
        "                ## Формат\n",
        "                Markdown\n",
        "                \"\"\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "        Messages(\n",
        "            role=MessagesRole.SYSTEM,\n",
        "            content=(\n",
        "                \"\"\"\n",
        "                Ты полезный ассистент для тестирования ГигаЧата. Твоя задача отвечать студенту на учебные вопросы\n",
        "                Отвечай кратко и ёмко!\n",
        "                ## Шаблон ответа:\n",
        "                {\n",
        "                  \"defenition\": \"\",\n",
        "                  \"properties\": \"\",\n",
        "                  \"roles\": \"\"\n",
        "                }\n",
        "                ## Формат\n",
        "                JSON\n",
        "                \"\"\"\n",
        "            )\n",
        "        ),\n",
        "        Messages(\n",
        "            role=MessagesRole.USER,\n",
        "            content=MESSAGE\n",
        "        ),\n",
        "    ]"
      ],
      "metadata": {
        "id": "twj1-1ypgMKn"
      },
      "id": "twj1-1ypgMKn",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "f4ded0d7-c55d-43b3-82f8-8f6511106e24",
      "metadata": {
        "id": "f4ded0d7-c55d-43b3-82f8-8f6511106e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "aa0e251d-5b65-447b-b599-1f0d27d7c895"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\n{\n  \"defenition\": \"Привет! Как могу помочь?\",\n  \"properties\": \"\",\n  \"roles\": \"\"\n}"
          },
          "metadata": {}
        }
      ],
      "source": [
        "payload = Chat(\n",
        "    messages=messages,\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        ")\n",
        "\n",
        "response = model.chat(payload)\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8050f0b9-75b9-4ad2-83ad-c612346f4b94",
      "metadata": {
        "id": "8050f0b9-75b9-4ad2-83ad-c612346f4b94"
      },
      "source": [
        "# Функции и Актуализация запросов к модели\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ef4894e5-aebe-40dc-bda2-f6c99c839a68",
      "metadata": {
        "id": "ef4894e5-aebe-40dc-bda2-f6c99c839a68"
      },
      "outputs": [],
      "source": [
        "def search_ddg(search_query):\n",
        "    \"\"\"Поиск в DuckDuckGo.\n",
        "        Полезен, когда нужно ответить на вопросы о текущих событиях.\n",
        "        Входными данными должен быть поисковый запрос.\"\"\"\n",
        "    return DDGS().text(search_query, max_results=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "0a2d015e-bf0f-4239-9aa0-b2955430b534",
      "metadata": {
        "id": "0a2d015e-bf0f-4239-9aa0-b2955430b534",
        "outputId": "655a5459-c5c5-4fab-e907-963c0115b841",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'Привет or Здравствуйте? : r/russian - Reddit', 'href': 'https://www.reddit.com/r/russian/comments/16ckcbe/привет_or_здравствуйте/', 'body': 'Sep 7, 2023 · The word \"Здравствуйте\" is used to greet adults, it is a respectful form. And \"Привет\" is just the \"Hello\" you say to a friend, for example. это всем привет или привет всем? : r/russian - Reddit What is the difference between \"привет\" аnd \"приветик\"? : r/russian More results from www.reddit.com'}\n"
          ]
        }
      ],
      "source": [
        "results = search_ddg(MESSAGE)\n",
        "print(results[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "8759fdbc-0e1d-4869-97d6-292bf897c9a3",
      "metadata": {
        "id": "8759fdbc-0e1d-4869-97d6-292bf897c9a3"
      },
      "outputs": [],
      "source": [
        "search_func = Function(\n",
        "    name=\"duckduckgo_search\",\n",
        "    description=\"Поиск в DuckDuckGo для получения актуальной информации.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\"query\": {\"type\": \"string\"}},\n",
        "        required=[\"query\"],\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4vbqWVKhSGkk"
      },
      "id": "4vbqWVKhSGkk"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "0da5d2fd-9e50-4286-8458-3d04fc662593",
      "metadata": {
        "id": "0da5d2fd-9e50-4286-8458-3d04fc662593",
        "outputId": "4567ce06-bc37-4e5f-ac21-3336c0b3e4d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "role='assistant' content='Привет! Как настроение?' function_call=None name=None attachments=None data_for_context=None functions_state_id='019b4277-0846-7664-8311-e21af0e45552' reasoning_content=None id_=None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stop'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "messages = [\n",
        "        Messages(role=MessagesRole.USER, content=MESSAGE)\n",
        "    ]\n",
        "chat = Chat(messages=messages, functions=[search_func])\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "print(message)\n",
        "resp.finish_reason"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "b4d749f3-6904-43cf-a895-440fd1250010",
      "metadata": {
        "id": "b4d749f3-6904-43cf-a895-440fd1250010",
        "outputId": "a6221381-36bd-4942-fd3c-0ce566089984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "МОДЕЛЬ ОТВЕТИЛА СРАЗУ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\nПривет! Как настроение?"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Если модель хочет вызвать функцию\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func_name = message.function_call.name\n",
        "    query = message.function_call.arguments[\"query\"]\n",
        "\n",
        "    # Выполняем функцию\n",
        "    result = search_ddg(query)\n",
        "\n",
        "    # Шаг 2: отправляем результат обратно модели\n",
        "    messages.extend([\n",
        "        message,  # сообщение с function_call\n",
        "        Messages(role=MessagesRole.FUNCTION, content=json.dumps({\"result\": result}, ensure_ascii=False))\n",
        "    ])\n",
        "    final_resp = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response = final_resp.message.content\n",
        "else:\n",
        "    # Модель ответила сразу\n",
        "    print('МОДЕЛЬ ОТВЕТИЛА СРАЗУ')\n",
        "    response = message.content\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "330c2c47-3f53-46e4-90f0-1e805f8b4213",
      "metadata": {
        "id": "330c2c47-3f53-46e4-90f0-1e805f8b4213"
      },
      "source": [
        "### Упражения\n",
        "1. Измените поле `desription` описания функции, например на\n",
        "    * \"Используй ТОЛЬКО для вопросов о погоде.\"\n",
        "    * \"Никогда не используй этот поиск.\"\n",
        "    * \"Это функция для поиска рецептов блюд.\"\n",
        "Проверьте как это скажется на результатах.\n",
        "2. Измените значение `max_results` в диапазоне 1 - 10, провеврьте как это скажется на качестве ответа\n",
        "3. Добавьте к примеру системный промпт, например \"Ты — помощник, который ВСЕГДА ищет информацию в интернете, даже если знаешь ответ.\"\n",
        "4. Добавьте функцию текущей даты к списку функций запроса.\n",
        "```python\n",
        "   def get_current_date():\n",
        "        \"\"\"Возвращает текущую дату в формате ГГГГ-ММ-ДД.\"\"\"\n",
        "        from datetime import datetime\n",
        "        return datetime.now().strftime(\"%Y-%m-%d\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_current_date():\n",
        "  from datetime import datetime\n",
        "  now = datetime.now()\n",
        "  today = datetime(year=now.year, month=now.month-1, day=5) # Обманем gigachat\n",
        "  return today.strftime(\"%Y-%m-%d\")"
      ],
      "metadata": {
        "id": "a8VMnnDun0CY"
      },
      "id": "a8VMnnDun0CY",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_current_date())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__jXjFNsn-GB",
        "outputId": "1579da12-f83b-48d1-c0f6-2e6efdcc6567"
      },
      "id": "__jXjFNsn-GB",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_func = Function(\n",
        "    name=\"get_current_date\",\n",
        "    description=\"Узнать дату сегодня (сегодняшний день, сегодняшнее число)\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={},\n",
        "        required=[],\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "RoThkfp0oAnX"
      },
      "id": "RoThkfp0oAnX",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_func = [\n",
        "    Function(\n",
        "      name=\"duckduckgo_search\",\n",
        "      description=\"Поиск в DuckDuckGo для получения актуальной информации. Используй ТОЛЬКО для погоды и даты\",\n",
        "      parameters=FunctionParameters(\n",
        "          type=\"object\",\n",
        "          properties={\"query\": {\"type\": \"string\"}},\n",
        "          required=[\"query\"],\n",
        "          )\n",
        "    ),\n",
        "    Function(\n",
        "      name=\"get_current_date\",\n",
        "      description=\"Узнать дату сегодня (сегодняшний день, сегодняшнее число)\",\n",
        "      parameters=FunctionParameters(\n",
        "          type=\"object\",\n",
        "          properties={},\n",
        "          required=[],\n",
        "        ),\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "W6jgnXjYmJ-7"
      },
      "id": "W6jgnXjYmJ-7",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "e8350c04-5208-4cf8-95d7-ecd64e3db3b3",
      "metadata": {
        "id": "e8350c04-5208-4cf8-95d7-ecd64e3db3b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f845d75-675b-43aa-a6e0-d261d1eaf2af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "role='assistant' content='' function_call=FunctionCall(name='get_current_date', arguments={}) name=None attachments=None data_for_context=None functions_state_id='019b4277-740e-70ff-997b-80541529df18' reasoning_content=None id_=None\n"
          ]
        }
      ],
      "source": [
        "MESSAGE = \"Какое сегодня число?\"\n",
        "\n",
        "messages = [\n",
        "        Messages(role=MessagesRole.USER, content=MESSAGE)\n",
        "    ]\n",
        "\n",
        "chat = Chat(messages=messages, functions=search_func, max_tokens=100)\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "print(message)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Если модель хочет вызвать функцию\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func_name = message.function_call.name\n",
        "\n",
        "    # Выполняем функцию\n",
        "    if func_name == \"duckduckgo_search\":\n",
        "      query = message.function_call.arguments[\"query\"]\n",
        "      result = search_ddg(query)\n",
        "    elif func_name == \"get_current_date\":\n",
        "      result = get_current_date()\n",
        "\n",
        "    # Шаг 2: отправляем результат обратно модели\n",
        "    messages.extend([\n",
        "        message,  # сообщение с function_call\n",
        "        Messages(role=MessagesRole.FUNCTION, content=json.dumps({\"result\": result}, ensure_ascii=False))\n",
        "    ])\n",
        "    final_resp = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response = final_resp.message.content\n",
        "else:\n",
        "    # Модель ответила сразу\n",
        "    print('МОДЕЛЬ ОТВЕТИЛА СРАЗУ')\n",
        "    response = message.content\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "T4j4F5JMoVFF",
        "outputId": "dfa4515a-d72e-4a2a-c334-f14b55e488d1"
      },
      "id": "T4j4F5JMoVFF",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\nСегодня 5 ноября 2025 года."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4778da43-9f46-49e8-8c6b-dcbeab29fa6a",
      "metadata": {
        "id": "4778da43-9f46-49e8-8c6b-dcbeab29fa6a"
      },
      "source": [
        "## Упражения 2\n",
        "\n",
        "Создадим свой калькулятор при помощи функций `GigaChat`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "6dda6449-cdb8-422e-923d-329572489166",
      "metadata": {
        "id": "6dda6449-cdb8-422e-923d-329572489166"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def safe_calculate(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Выполняет математическое выражение.\n",
        "    Поддерживает: +, -, *, /, **, скобки, числа с точкой.\n",
        "    Безопасен: разрешает ТОЛЬКО математические символы.\n",
        "    \"\"\"\n",
        "    # Разрешённые символы: цифры, операторы, скобки, точка, пробелы\n",
        "    if not re.fullmatch(r'[\\d+\\-*/().\\s]+', expression):\n",
        "        return \"Ошибка: выражение содержит недопустимые символы.\"\n",
        "\n",
        "    try:\n",
        "        # Ограничиваем сложность (например, не даём выполнить 9**9**9)\n",
        "        if '^' in expression or len(expression) > 50:\n",
        "            return \"Ошибка: выражение слишком сложное или длинное.\"\n",
        "\n",
        "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
        "        return str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Ошибка вычисления: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "4387a9e3-15cc-416e-bd0d-87107b8f7178",
      "metadata": {
        "id": "4387a9e3-15cc-416e-bd0d-87107b8f7178",
        "outputId": "5c740036-a637-486e-cfa4-2c3124d4ab9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'243'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "safe_calculate('3*(4+5)**2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "7ccfa93f-9a97-41fb-ae91-7acca80eadb6",
      "metadata": {
        "id": "7ccfa93f-9a97-41fb-ae91-7acca80eadb6"
      },
      "outputs": [],
      "source": [
        "calculate_func = Function(\n",
        "    name=\"calculate\",\n",
        "    description=\"Выполняет математические вычисления. Передавай ТОЛЬКО выражение в виде строки, например: '2 + 3 * 4'.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"expression\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Математическое выражение (только цифры, +, -, *, /, **, скобки)\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"expression\"],\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "01bbf602-9bf9-421e-aeab-cb882584e722",
      "metadata": {
        "id": "01bbf602-9bf9-421e-aeab-cb882584e722"
      },
      "outputs": [],
      "source": [
        "message = 'Сколько будет 3*(4+5)**2'\n",
        "\n",
        "messages = [\n",
        "    Messages(role=MessagesRole.USER, content=message)\n",
        "]\n",
        "\n",
        "chat = Chat(messages=messages, functions=[calculate_func])\n",
        "\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func = message.function_call\n",
        "    if func.name == \"calculate\":\n",
        "        expr = func.arguments.get(\"expression\", \"\")\n",
        "        result = safe_calculate(expr)\n",
        "        # Возвращаем результат модели\n",
        "        messages.extend([\n",
        "            message,\n",
        "            Messages(role=MessagesRole.FUNCTION, content=result)\n",
        "        ])\n",
        "        # Получаем финальный ответ\n",
        "        final = model.chat(Chat(messages=messages)).choices[0]\n",
        "        response =  final.message.content\n",
        "else:\n",
        "    # Модель ответила без вычислений (например, объяснила задачу)\n",
        "    response = message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "3f920ef5-e42d-4419-957e-66ce8b60cd75",
      "metadata": {
        "id": "3f920ef5-e42d-4419-957e-66ce8b60cd75",
        "outputId": "b4c3c59d-ef3f-42de-fd63-064362aa5aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\nВыражение $3 \\times (4 + 5)^2$ равно 243."
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(\"<blockquote>\\n\\n\"+response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b42ecb18-022c-4307-8c63-a431b8213837",
      "metadata": {
        "id": "b42ecb18-022c-4307-8c63-a431b8213837"
      },
      "source": [
        "__Упражения__\n",
        "1. Сделайте проверку на sin/cos в функции калькулятора\n",
        "   \n",
        "2. Расширьте функционал калькулятора"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_func = Function(\n",
        "    name=\"calculate\",\n",
        "    description=\"Выполняет математические вычисления. Передавай ТОЛЬКО выражение в виде строки, например: '2 + 3 * 4'.\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"expression\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Математическое выражение (только цифры, +, -, *, /, **, скобки)\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"expression\"],\n",
        "    )\n",
        ")\n",
        "\n",
        "sin_func = Function(\n",
        "    name=\"sin\",\n",
        "    description=\"Находит синус выражения. ВАЖНО, сначала высчитай синусы, потом замени синусы на реальные значения и передай аргумент функции калькулятора\",\n",
        "    parameters=FunctionParameters(\n",
        "        type=\"object\",\n",
        "        properties={\n",
        "            \"value\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Значение угла в радианах\"\n",
        "            }\n",
        "        },\n",
        "        required=[\"value\"],\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "kZza6pPdsU2s"
      },
      "id": "kZza6pPdsU2s",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = 'Сколько будет 55*243?'\n",
        "\n",
        "messages = [\n",
        "    Messages(role=MessagesRole.USER, content=message)\n",
        "]\n",
        "\n",
        "chat = Chat(messages=messages, functions=[calculate_func, sin_func], max_tokens=100)\n",
        "\n",
        "resp = model.chat(chat).choices[0]\n",
        "message = resp.message\n",
        "\n",
        "if resp.finish_reason == \"function_call\":\n",
        "    func = message.function_call\n",
        "    if func.name == \"calculate\":\n",
        "        print(\"Калькулирую!\")\n",
        "        expr = func.arguments.get(\"expression\", \"\")\n",
        "        result = safe_calculate(expr)\n",
        "    elif func.name == \"sin\":\n",
        "        value = func.arguments.get(\"value\", \"\")\n",
        "        print(\"Расчёты!\")\n",
        "        result = eval(f\"sin({value})\")\n",
        "    # Возвращаем результат модели\n",
        "    messages.extend([\n",
        "        message,\n",
        "        Messages(role=MessagesRole.FUNCTION, content=result)\n",
        "    ])\n",
        "    # Получаем финальный ответ\n",
        "    final = model.chat(Chat(messages=messages)).choices[0]\n",
        "    response =  final.message.content\n",
        "else:\n",
        "    # Модель ответила без вычислений (например, объяснила задачу)\n",
        "    response = message.content"
      ],
      "metadata": {
        "id": "GICchSqBs-Qp",
        "outputId": "422af047-70c1-4eb0-deb0-c11df72b27ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GICchSqBs-Qp",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Калькулирую!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "PQJ0J2k9vD3N",
        "outputId": "480ca015-cfe7-4c5b-be07-4cf66c9d3d2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PQJ0J2k9vD3N",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Произведение чисел 55 и 243 равно $ \\fbox{13365} $.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "d09d2294-0782-460f-bfdc-dc3cd52c125f",
      "metadata": {
        "id": "d09d2294-0782-460f-bfdc-dc3cd52c125f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab079f3-34a6-4678-f09d-c689d2ed314a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.0\n"
          ]
        }
      ],
      "source": [
        "from math import sin, cos, pi\n",
        "print(sin(3*pi/2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de6e24ea-1c04-4a74-bf83-9d69a5adf892",
      "metadata": {
        "id": "de6e24ea-1c04-4a74-bf83-9d69a5adf892"
      },
      "source": [
        "# <span style=\"color:red\">Опционально.</span> О более продвинутом пути к LLM-приложениям"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_gigachat"
      ],
      "metadata": {
        "id": "q36DqYcbxDZA",
        "outputId": "af466a89-7346-4d0b-c09e-c1a119154c78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "id": "q36DqYcbxDZA",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_gigachat\n",
            "  Downloading langchain_gigachat-0.3.12-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: gigachat<0.2.0,>=0.1.41.post1 in /usr/local/lib/python3.12/dist-packages (from langchain_gigachat) (0.1.43)\n",
            "Collecting langchain-core<0.4,>=0.3 (from langchain_gigachat)\n",
            "  Downloading langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting types-requests<3.0,>=2.32 (from langchain_gigachat)\n",
            "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: httpx<1 in /usr/local/lib/python3.12/dist-packages (from gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1 in /usr/local/lib/python3.12/dist-packages (from gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (2.12.3)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (0.4.59)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4,>=0.3->langchain_gigachat) (25.0)\n",
            "Requirement already satisfied: urllib3>=2 in /usr/local/lib/python3.12/dist-packages (from types-requests<3.0,>=2.32->langchain_gigachat) (2.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4,>=0.3->langchain_gigachat) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (2.32.4)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (0.12.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat<0.2.0,>=0.1.41.post1->langchain_gigachat) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4,>=0.3->langchain_gigachat) (3.4.4)\n",
            "Downloading langchain_gigachat-0.3.12-py3-none-any.whl (27 kB)\n",
            "Downloading langchain_core-0.3.80-py3-none-any.whl (450 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.8/450.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, langchain-core, langchain_gigachat\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.1\n",
            "    Uninstalling langchain-core-1.2.1:\n",
            "      Successfully uninstalled langchain-core-1.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.3.80 which is incompatible.\n",
            "langchain 1.2.0 requires langchain-core<2.0.0,>=1.2.1, but you have langchain-core 0.3.80 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.3.80 langchain_gigachat-0.3.12 types-requests-2.32.4.20250913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "j9819xjLxfRu",
        "outputId": "22f2622b-dca7-4248-8d54-ec035c4f4f44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "id": "j9819xjLxfRu",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Collecting langchain-core<2.0.0,>=1.2.1 (from langchain)\n",
            "  Downloading langchain_core-1.2.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.5.0)\n",
            "Downloading langchain_core-1.2.4-py3-none-any.whl (477 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m477.4/477.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.80\n",
            "    Uninstalling langchain-core-0.3.80:\n",
            "      Successfully uninstalled langchain-core-0.3.80\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-gigachat 0.3.12 requires langchain-core<0.4,>=0.3, but you have langchain-core 1.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBbVejG6jN3V",
        "outputId": "d46091e6-09b2-4173-fb69-12c829f644d6",
        "collapsed": true
      },
      "id": "cBbVejG6jN3V",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.59)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-text-splitters-1.1.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "57a311e9-7a90-4aef-801e-010ec53b3e89",
      "metadata": {
        "id": "57a311e9-7a90-4aef-801e-010ec53b3e89"
      },
      "outputs": [],
      "source": [
        "from langchain_gigachat import GigaChat\n",
        "# from langchain_core.tools import tool\n",
        "# from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, FunctionMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "219a10ac-9507-43eb-90f8-9143b709ded6",
      "metadata": {
        "id": "219a10ac-9507-43eb-90f8-9143b709ded6"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "62cc963b-0bd4-4683-b651-16903e4bdb0f",
      "metadata": {
        "id": "62cc963b-0bd4-4683-b651-16903e4bdb0f"
      },
      "outputs": [],
      "source": [
        "# Инициализация модели\n",
        "llm = GigaChat(\n",
        "    model=\"GigaChat-2\",\n",
        "    credentials=auth,\n",
        "    verify_ssl_certs=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1930148-9153-4ad6-8acb-89f101e98a13",
      "metadata": {
        "id": "a1930148-9153-4ad6-8acb-89f101e98a13"
      },
      "source": [
        "В `Langchain` есть классы `HumanMessage`, `SystemMessage` и `AssistantMessage` для удобного представления словарей сообщений.\n",
        "\n",
        "Например вмето записи сообщания в стиле:\n",
        "```json\n",
        "{'role': 'system',\n",
        "'content': 'Отвечай как бывалый пират. Пусть тебя зовут Генри Морган.'\n",
        "}\n",
        "```\n",
        "теперь можем записать:\n",
        "```python\n",
        "SystemMessage(content='Отвечай как бывалый пират. Пусть тебя зовут Генри Морган.')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "812ee915-ffd2-405f-acda-fedcf7fb476d",
      "metadata": {
        "id": "812ee915-ffd2-405f-acda-fedcf7fb476d"
      },
      "outputs": [],
      "source": [
        "msg = [SystemMessage(content='Отвечай как инженр-датасаинтист с 20 летним опытом. Используй Markdown разметку ответа. Ответ не должен быть длинее 10 строк')]\n",
        "\n",
        "question = \"Какие приемущества может дать langchain в работе с GigaChat\"\n",
        "\n",
        "msg.append(HumanMessage(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "396a1ef5-a52c-459e-9ec8-0b1f1e6ca97d",
      "metadata": {
        "scrolled": true,
        "id": "396a1ef5-a52c-459e-9ec8-0b1f1e6ca97d",
        "outputId": "c19ef640-7d9d-4608-a4b3-7d1ade636371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\n**Преимущества использования LangChain с GigaChat:**\n\n- **Интеграция внешних источников данных:** возможность легко подключать и использовать внешние базы знаний, API и документы.\n- **Управление цепочками обработки:** автоматизация сложных последовательностей запросов и ответов, улучшение логики диалога.\n- **Модульность и расширяемость:** гибкость настройки, добавление новых компонентов (например, векторных баз данных или обработчиков контекста).\n- **Обучение моделей на больших объемах данных:** интеграция больших коллекций текстов для повышения качества ответов.\n- **Улучшение диалогового опыт"
          },
          "metadata": {}
        }
      ],
      "source": [
        "results = llm.invoke(msg).content[:600]\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e36f412e-86b4-46d9-8283-db22049ef71a",
      "metadata": {
        "id": "e36f412e-86b4-46d9-8283-db22049ef71a"
      },
      "source": [
        "При помощи класса `AIMessage` `LangChain` позволяет сохранить ответ на первое сообщение и использовать этот результат при вторичном запросе. В нашем случае попросим уточнить `GigaChat` примеры кода для нашего запроса.\n",
        "\n",
        "В примере будем использовать метод `invoke` - часть унифицированного `Runnable API (LangChain 0.1.0+)`.\n",
        "Прямой вызов - устаревший подход, может быть удален в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "9b7d1357-6954-4d58-9b10-92b6d57314e5",
      "metadata": {
        "scrolled": true,
        "id": "9b7d1357-6954-4d58-9b10-92b6d57314e5",
        "outputId": "5a0a81e7-dbbf-49e7-bf3c-da6b62409227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<blockquote>\n\n# 📄 Пример использования цепочки (chain) с GigaChat (LangChain-GigaChat)\n\n## ⚙️ Описание задачи:\nНеобходимо создать простую цепочку обработки запроса пользователя на основе GigaChat:\n- пользователь задает вопрос;\n- модель анализирует запрос и генерирует ответ;\n- результат выводится пользователю.\n\n## 💻 Реализация\n\n```python\nfrom langchain_gigachat import GigachatAPI\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\n\n# Инициализация API клиента\napi = GigachatAPI(api_key=\"<твой_api_ключ>\")\n\n# Создание шаблона запроса к модели\nprompt_template = PromptTemplate(\n    input_variables=[\"question\"],\n    template=\"Ответь на следующий вопрос: {question}\"\n)\n\n# Определение структуры цепочки\nllm_chain = LLMChain(\n    llm=api,\n    prompt=prompt_template\n)\n\n# Получение вопроса от пользователя\nquestion = \"Какая погода сегодня в Москве?\"\n\n# Выполнение цепочки\nresponse = llm_chain.run(question)\n\nprint(response)\n```\n\n## 🔍 Результат выполнения:\n```\nСегодня в Москве солнечно, температура +15°C.\n```\n\nТаким образом, используя цепочку из простого шаблона и вызова модели, можно эффективно организовать взаимодействие пользователя с GigaChat."
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Получаем ответ\n",
        "response = llm.invoke(msg)  # Используем invoke вместо прямого вызова\n",
        "results = response.content[:600]\n",
        "\n",
        "# Сохраняем ответ в историю\n",
        "msg.append(AIMessage(content=results))\n",
        "\n",
        "# Пример продолжения диалога с историей\n",
        "follow_up_question = \"Можешь привести конкретный пример использования цепочки (chain) с GigaChat (langchain_gigachat)?\"\n",
        "msg.append(HumanMessage(content=follow_up_question))\n",
        "\n",
        "# Получаем ответ с учетом всей истории\n",
        "follow_up_response = llm.invoke(msg)\n",
        "msg.append(AIMessage(content=follow_up_response.content))\n",
        "\n",
        "display(Markdown(\"<blockquote>\\n\\n\"+follow_up_response.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "502c9b23-24bc-4ca2-ab8f-0fa4b91c9fcf",
      "metadata": {
        "id": "502c9b23-24bc-4ca2-ab8f-0fa4b91c9fcf"
      },
      "source": [
        "Попробуем также в целях демонстрации возможностей `langchain` создать цепочку рассуджений. Для этого воспользуемся специальным классом `PromptTemplate`, который позволяет создавать шаблоны запросов аналогично f-функциям"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "662eef72-9eba-4ddf-b8fe-405355191356",
      "metadata": {
        "id": "662eef72-9eba-4ddf-b8fe-405355191356",
        "outputId": "9b60a321-38f9-47cf-d0a0-262f02b3dfb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Задача:\n** В классе 30 учеников. 40% из них - девочки. Сколько мальчиков в классе?\n----------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Решение:\n\n** content='### Шаг 1. Понимание условия задачи\\n\\nНам известно, что всего в классе 30 учеников, и 40% из них — девочки. Нужно узнать количество мальчиков.\\n\\n### Шаг 2. Логическое разбиение решения\\n\\n- Найдем сначала число девочек (по условию задачи).\\n- Затем вычтем найденное число девочек из общего числа учеников, чтобы получить число мальчиков.\\n\\n### Шаг 3. Вычисление количества девочек\\n\\n1. Найдем процентное соотношение учеников-девочек от общего числа учеников:\\n   \\n\\n$$\\n   \\\\text{Количество девочек} = 30 \\\\times 40\\\\% = 30 \\\\times 0{,}4 = 12\\n   $$\\n\\n### Шаг 4. Нахождение количества мальчиков\\n\\nТеперь, зная количество девочек, найдем число мальчиков:\\n\\n$$\\n\\\\text{Количество мальчиков} = \\\\text{Общее число учеников} - \\\\text{Количество девочек}\\n$$\\n\\n$$\\n\\\\text{Количество мальчиков} = 30 - 12 = 18\\n$$\\n\\n### Шаг 5. Проверка правильности рассуждений\\n\\nПроверим результат:\\n- Общее число учеников составляет 30 человек.\\n- Девочки составляют 40%, значит 12 человек.\\n- Оставшиеся ученики — мальчики, следовательно, $30 - 12 = 18$ мальчиков.\\n\\nТаким образом, проверка подтверждает корректность расчетов.\\n\\n### Окончательный ответ\\n\\nВ классе 18 мальчиков.' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 99, 'completion_tokens': 310, 'total_tokens': 409, 'precached_prompt_tokens': 2}, 'model_name': 'GigaChat-2:2.0.28.2', 'x_headers': {'x-request-id': 'e31d9a39-644f-4f55-985d-0f0ecd507ecf', 'x-session-id': 'ecd6719f-b907-4a9e-848d-349317deda1c', 'x-client-id': None}, 'finish_reason': 'stop'} id='e31d9a39-644f-4f55-985d-0f0ecd507ecf' usage_metadata={'output_tokens': 310, 'input_tokens': 99, 'total_tokens': 409, 'input_token_details': {'cache_read': 2}}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Задача:\n** Книга стоит 500 рублей. После скидки цена снизилась на 20%. Сколько стоит книга после скидки?\n----------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Решение:\n\n** content='### Шаг 1. Понимание условия задачи\\nНам дана исходная стоимость книги — **500 рублей**. После проведения скидки её цена уменьшилась на **20%** от первоначальной стоимости. Нужно узнать, сколько будет стоить книга после этой скидки.\\n\\n### Шаг 2. Разбиваем решение на логические шаги\\n\\n- Рассчитаем размер скидки (в рублях).\\n- Вычислим итоговую цену книги после применения скидки.\\n\\n### Шаг 3. Выполняем вычисления\\n\\n#### 1. Найдём размер скидки\\nРазмер скидки составляет 20% от начальной цены книги:\\n$$ \\n\\\\text{Скидка} = 500 \\\\, \\\\text{руб.} \\\\times 20\\\\% = 500 \\\\times 0{,}2 = 100 \\\\, \\\\text{руб.}\\n$$\\n\\n#### 2. Определим итоговую цену книги после скидки\\nИзначальная цена минус скидка:\\n$$\\n\\\\text{Итоговая цена} = 500 \\\\, \\\\text{руб.} - 100 \\\\, \\\\text{руб.} = 400 \\\\, \\\\text{руб.}\\n$$\\n\\n### Шаг 4. Проверяем правильность рассуждений\\nМы последовательно выполнили следующие операции:\\n- нашли процентную скидку от общей суммы,\\n- вычли полученную сумму скидки из изначальной цены книги.\\nРезультат имеет экономический смысл, поскольку цена стала меньше после скидки.\\n\\n### Шаг 5. Формулируем окончательный ответ\\nПосле скидки книга будет стоить **400 рублей**.' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 101, 'completion_tokens': 321, 'total_tokens': 422, 'precached_prompt_tokens': 3}, 'model_name': 'GigaChat-2:2.0.28.2', 'x_headers': {'x-request-id': 'd9e82003-6be9-4b8d-bf63-183207e8d319', 'x-session-id': '384ff35b-c767-45ac-810c-d0418c74b3be', 'x-client-id': None}, 'finish_reason': 'stop'} id='d9e82003-6be9-4b8d-bf63-183207e8d319' usage_metadata={'output_tokens': 321, 'input_tokens': 101, 'total_tokens': 422, 'input_token_details': {'cache_read': 3}}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Создаем шаблон для Chain of Thought\n",
        "cot_template = \"\"\"\n",
        "Реши задачу шаг за шагом:\n",
        "\n",
        "Задача: {problem}\n",
        "\n",
        "Пожалуйста:\n",
        "1. Сначала пойми, что дано и что нужно найти\n",
        "2. Разбей решение на логические шаги\n",
        "3. Выполни вычисления для каждого шага\n",
        "4. Проверь правильность рассуждений\n",
        "5. Сформулируй окончательный ответ\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cot_prompt = ChatPromptTemplate.from_template(\n",
        "    cot_template\n",
        ")\n",
        "\n",
        "cot_chain = cot_prompt | llm  # создание цепочки через pipe\n",
        "\n",
        "# Создаем цепочку\n",
        "# cot_chain = LLMChain(llm=llm, prompt=cot_prompt)\n",
        "# news = \"Вчера в Екатеринбурге произошло 3 ДТП и прорвало трубу на Ленина.\"\n",
        "# response = cot_chain.invoke({\"news_text\": news})\n",
        "# print(response.content)\n",
        "\n",
        "# Используем\n",
        "problems = [\n",
        "    \"В классе 30 учеников. 40% из них - девочки. Сколько мальчиков в классе?\",\n",
        "    \"Книга стоит 500 рублей. После скидки цена снизилась на 20%. Сколько стоит книга после скидки?\",\n",
        "]\n",
        "\n",
        "for problem in problems:\n",
        "    result = cot_chain.invoke(problem)\n",
        "    display(Markdown(f\"**Задача:\\n** {problem}\\n----------------------------\"))\n",
        "    display(Markdown(f\"**Решение:\\n\\n** {result}\"))\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dbd67a2-b43b-48f9-92fc-6606809084e8",
      "metadata": {
        "id": "9dbd67a2-b43b-48f9-92fc-6606809084e8"
      },
      "source": [
        "### Упражнение:\n",
        "\n",
        "Проверьте качество работы цепочки рассуждений для разных категорий вопросов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "fca45eef-48b9-46e2-be61-877e56d11b06",
      "metadata": {
        "id": "fca45eef-48b9-46e2-be61-877e56d11b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17a14fc9-f6de-4b63-b8b6-0834c15b95e8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Задача:\n** Каков радиус Земли?\n----------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Шаг 1. Понимание условия задачи\nНам известно, что Земля имеет форму близкую к сферической (с небольшим сплюснутым полюсом). Нам нужно определить её радиус — расстояние от центра до любой точки поверхности планеты.\n\n### Шаг 2. Разбиение решения на логические шаги\n1. Изучить известные данные о размерах Земли.\n2. Найти среднее значение радиуса сферы, учитывая, что планета немного сплюснута.\n3. Рассчитать средний радиус, используя геометрические свойства эллипсоида вращения.\n\n### Шаг 3. Вычисление среднего радиуса Земли\n- Известно, что радиусы Земли в среднем составляют:\n  - Экваториальный радиус (радиус вдоль экватора): примерно $6\\,378\\,137$ метров.\n  - Полярный радиус (радиус вдоль меридианов): примерно $6\\,356\\,752$ метров.\n  \nСредний радиус Земли ($R$) можно приближенно рассчитать следующим образом:\n$$ R = \\frac{R_{\\text{экв}} + R_{\\text{пол}}}{2} $$\n\nПодставим значения:\n$$ R = \\frac{6\\,378\\,137 \\,+\\, 6\\,356\\,752}{2} = \\frac{12\\,734\\,890}{2} = 6\\,367\\,445 \\, м $$\n\nДля удобства измерений принято использовать километры:\n$$ R \\approx 6\\,367 \\, км $$\n\nОднако стандартное общепринятое значение среднего радиуса Земли чуть больше:\n\n$$ R_{\\text{средн}} = 6\\,371\\,000 \\, м = 6\\,371 \\, км $$\n\nТаким образом, округлим полученное нами значение до стандартного международного стандарта.\n\n### Шаг 4. Проверка правильности рассуждений\nМы использовали арифметическое среднее двух известных значений радиусов Земли, которые довольно точно соответствуют фактическому размеру нашей планеты. Результат совпадает с принятым международным значением радиуса Земли.\n\n### Шаг 5. Окончательный ответ\nРадиус Земли составляет приблизительно **6371 километр**."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Задача:\n** Рецепт пельменей\n----------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Шаг 1. Понимание условия задачи\n\nДано:\n- Нам известен рецепт приготовления пельменей (по рецепту указано количество ингредиентов и пропорции).\n- Необходимо рассчитать необходимое количество продуктов для заданного количества порций пельменей.\n\n### Шаг 2. Определение неизвестной величины\n\nНеобходимо определить, сколько граммов муки, мяса, воды и соли потребуется для заданного числа порций пельменей.\n\n### Шаг 3. Логическое разбиение решения на этапы\n\n1. **Определение массы одного пельменя** — определим массу одного изделия исходя из рецепта.\n2. **Расчет общего веса пельменей** — умножением массы одного пельменя на общее число порций.\n3. **Подсчет необходимого сырья** — зная общую массу готовых пельменей, можем посчитать вес отдельных компонентов (мука, мясо, вода, соль), необходимых для получения данного объема пельменей.\n\n### Шаг 4. Вычисление\n\nПусть рецепт предусматривает следующие пропорции на 1 кг готовых пельменей:\n- Мука — 400 г\n- Мясо — 600 г\n- Вода — 80 мл\n- Соль — 10 г\n\nНужно приготовить 500 грамм пельменей.\n\n#### Этап 1. Расчёт массы одной порции пельменей\n$$ m_{\\text{порция}} = \\frac{\\text{масса готового продукта}}{\\text{количество порций}} = \\frac{1\\,кг}{10\\,порций} = 100\\,г $$\n\n#### Этап 2. Рассчитаем компоненты на 500 г пельменей\nТеперь рассчитаем, какое количество каждого ингредиента нам понадобится для 500 г пельменей.\n\n$$\nm_{\\text{муки}} = \\frac{400\\,г}{1000\\,г} \\times 500\\,г = 200\\,г\n$$\n\n$$\nm_{\\text{мяса}} = \\frac{600\\,г}{1000\\,г} \\times 500\\,г = 300\\,г\n$$\n\n$$\nm_{\\text{воды}} = \\frac{80\\,мл}{1000\\,мл} \\times 500\\,мл = 40\\,мл\n$$\n\n$$\nm_{\\text{соли}} = \\frac{10\\,г}{1000\\,г} \\times 500\\,г = 5\\,г\n$$\n\n### Шаг 5. Проверка правильности расчетов\n\nПроверим арифметику:\n- Масса муки: $\\frac{400}{1000} \\times 500 = 200$ г верно.\n- Масса мяса: $\\frac{600}{1000} \\times 500 = 300$ г верно.\n- Количество воды: $\\frac{80}{1000} \\times 500 = 40$ мл верно.\n- Массу соли легко проверить прямым делением: $\\frac{10}{1000} \\times 500 = 5$ г верно.\n\n### Окончательный ответ\n\nДля приготовления 500 г пельменей потребуется:\n- мука — 200 г,\n- мясо — 300 г,\n- вода — 40 мл,\n- соль — 5 г."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n"
          ]
        }
      ],
      "source": [
        "problems = [\n",
        "    \"Каков радиус Земли?\"\n",
        "]\n",
        "\n",
        "for problem in problems:\n",
        "    result = cot_chain.invoke(problem)\n",
        "    display(Markdown(f\"**Задача:\\n** {problem}\\n----------------------------\"))\n",
        "    display(Markdown(result.content))\n",
        "    print(\"---\")\n",
        "\n",
        "problems = [\n",
        "    \"Рецепт пельменей\"\n",
        "]\n",
        "\n",
        "for problem in problems:\n",
        "    result = cot_chain.invoke(problem)\n",
        "    display(Markdown(f\"**Задача:\\n** {problem}\\n----------------------------\"))\n",
        "    display(Markdown(result.content))\n",
        "    print(\"---\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}